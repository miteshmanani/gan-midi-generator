{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066d3ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.26.4\n",
      "PyTorch version: 2.2.2+cu118\n",
      "pretty_midi version: 0.2.10\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "import pretty_midi\n",
    "print(\"pretty_midi version:\", pretty_midi.__version__)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "if cuda_available:\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    \n",
    "    # Graphics card models\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No CUDA-compatible GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d947fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, note_dim, time_steps, num_conditions):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.condition_dim = num_conditions\n",
    "\n",
    "        # Condition embedding\n",
    "        self.condition_embed = nn.Embedding(num_conditions, 32)\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(4, 4), stride=(\n",
    "            2, 2), padding=(1, 1))  # Output: (64, 16)\n",
    "        self.leaky_relu1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(\n",
    "            4, 4), stride=(2, 2), padding=(1, 1))  # Output: (32, 8)\n",
    "        self.leaky_relu2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=(\n",
    "            4, 4), stride=(2, 2), padding=(1, 1))  # Output: (16, 4)\n",
    "        self.leaky_relu3 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=(\n",
    "            4, 4), stride=(2, 2), padding=(1, 1))  # Output: (8, 2)\n",
    "        self.leaky_relu4 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(512 * 8 * 2 + 32, 1)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        if x.dim() != 4 or x.size(1) != 1:\n",
    "            x = x.unsqueeze(1)  # [batch_size, 1, 128, 32]\n",
    "\n",
    "        # Embed condition\n",
    "        c = self.condition_embed(condition)  # [batch_size, 32]\n",
    "\n",
    "        # Apply convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.leaky_relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.leaky_relu4(x)\n",
    "        x = self.flatten(x)  # [batch_size, 512 * 8 * 2]\n",
    "\n",
    "        # Concatenate condition embedding and apply fully connected layer\n",
    "        x = torch.cat([x, c], dim=1)  # [batch_size, 512 * 8 * 2 + 32]\n",
    "        return self.fc(x)  # [batch_size, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, note_dim, time_steps, num_conditions):\n",
    "        super(Generator, self).__init__()\n",
    "        self.note_dim = note_dim  # 128\n",
    "        self.time_steps = time_steps  # 32\n",
    "        self.condition_dim = num_conditions\n",
    "\n",
    "        # Condition embedding\n",
    "        self.condition_embed = nn.Embedding(num_conditions, 32)\n",
    "\n",
    "        # Project latent vector + condition\n",
    "        self.project = nn.Linear(latent_dim + 32, 256 * 8 * 4)\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.batch_norm1 = nn.BatchNorm2d(256)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.conv_transpose1 = nn.ConvTranspose2d(\n",
    "            256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))  # (16, 8)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.conv_transpose2 = nn.ConvTranspose2d(128, 64, kernel_size=(\n",
    "            4, 4), stride=(2, 2), padding=(1, 1))  # (32, 16)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU(True)\n",
    "        self.conv_transpose3 = nn.ConvTranspose2d(64, 32, kernel_size=(\n",
    "            4, 4), stride=(2, 2), padding=(1, 1))  # (64, 32)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(32)\n",
    "        self.relu4 = nn.ReLU(True)\n",
    "        self.conv_transpose4 = nn.ConvTranspose2d(32, 1, kernel_size=(\n",
    "            2, 1), stride=(2, 1), padding=(0, 0))  # (128, 32)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z, condition):\n",
    "        # Embed condition\n",
    "        c = self.condition_embed(condition)  # (batch_size, 32)\n",
    "        x = torch.cat([z, c], dim=1)  # (batch_size, latent_dim + 32)\n",
    "        x = self.project(x).view(-1, 256, 8, 4)  # (batch_size, 256, 8, 4)\n",
    "\n",
    "        # Apply layers explicitly\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv_transpose1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv_transpose2(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv_transpose3(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv_transpose4(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x.squeeze(1)  # (batch_size, 128, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d797518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import visualkeras\n",
    "\n",
    "class GANTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.generator = Generator(\n",
    "            config.latent_dim, config.note_dim, config.time_steps, config.num_keys).to(self.device)\n",
    "        self.discriminator = Discriminator(\n",
    "            config.note_dim, config.time_steps, config.num_keys).to(self.device)\n",
    "        self.optimizer_G = optim.Adam(self.generator.parameters(\n",
    "        ), lr=config.lr, betas=(config.beta1, config.beta2))\n",
    "        self.optimizer_D = optim.Adam(self.discriminator.parameters(\n",
    "        ), lr=config.lr, betas=(config.beta1, config.beta2))\n",
    "        self.data_loader = DataLoader(\n",
    "            config.data_dir, max_files=config.max_files)\n",
    "        self.midi_converter = MidiConverter()\n",
    "        os.makedirs(config.output_dir, exist_ok=True)\n",
    "\n",
    "    def compute_gradient_penalty(self, real_samples, fake_samples, condition):\n",
    "        if real_samples.shape != fake_samples.shape:\n",
    "            raise ValueError(\n",
    "                f\"Shape mismatch: real_samples {real_samples.shape}, fake_samples {fake_samples.shape}\")\n",
    "        alpha = torch.rand(real_samples.size(0), 1, 1, device=self.device)\n",
    "        alpha = alpha.expand(real_samples.size(\n",
    "            0), real_samples.size(1), real_samples.size(2))\n",
    "        interpolates = (alpha * real_samples + (1 - alpha)\n",
    "                        * fake_samples).requires_grad_(True)\n",
    "        d_interpolates = self.discriminator(interpolates, condition)\n",
    "        fake = torch.ones(real_samples.size(0), 1, device=self.device)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=fake,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gradient_penalty\n",
    "\n",
    "    def evaluate_piano_roll(self, piano_roll):\n",
    "        note_density = np.mean(piano_roll)\n",
    "        pitch_counts = np.sum(piano_roll, axis=1)\n",
    "        pitch_probs = pitch_counts / (pitch_counts.sum() + 1e-10)\n",
    "        pitch_entropy = -np.sum([p * np.log2(p + 1e-10)\n",
    "                                for p in pitch_probs if p > 0])\n",
    "        return {\"note_density\": note_density, \"pitch_entropy\": pitch_entropy}\n",
    "\n",
    "    def validate_generator_output(self):\n",
    "        with torch.no_grad():\n",
    "            test_z = torch.randn(1, self.config.latent_dim, device=self.device)\n",
    "            test_key = torch.tensor([0], device=self.device)\n",
    "            test_output = self.generator(test_z, test_key)\n",
    "            assert test_output.shape[1:] == (self.config.note_dim, self.config.time_steps), \\\n",
    "                f\"Generator output shape mismatch: {test_output.shape}\"\n",
    "\n",
    "    def train(self):\n",
    "        self.validate_generator_output()\n",
    "        data, key_labels = self.data_loader.load_data()\n",
    "        data = data.to(self.device)\n",
    "        key_labels = key_labels.to(self.device)\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            # Train Discriminator\n",
    "            for _ in range(self.config.n_critic):\n",
    "                idx = np.random.randint(\n",
    "                    0, data.shape[0], self.config.batch_size)\n",
    "                real_samples = data[idx]\n",
    "                key_cond = key_labels[idx]\n",
    "                z = torch.randn(self.config.batch_size,\n",
    "                                self.config.latent_dim, device=self.device)\n",
    "                fake_samples = self.generator(z, key_cond)\n",
    "                real_loss = - \\\n",
    "                    torch.mean(self.discriminator(real_samples, key_cond))\n",
    "                fake_loss = torch.mean(self.discriminator(\n",
    "                    fake_samples.detach(), key_cond))\n",
    "                gradient_penalty = self.compute_gradient_penalty(\n",
    "                    real_samples, fake_samples, key_cond)\n",
    "                d_loss = real_loss + fake_loss + \\\n",
    "                    self.config.gradient_penalty_weight * gradient_penalty\n",
    "                self.optimizer_D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "            # Train Generator\n",
    "            z = torch.randn(self.config.batch_size,\n",
    "                            self.config.latent_dim, device=self.device)\n",
    "            key_cond = torch.randint(\n",
    "                0, self.config.num_keys, (self.config.batch_size,), device=self.device)\n",
    "            fake_samples = self.generator(z, key_cond)\n",
    "            g_loss = -torch.mean(self.discriminator(fake_samples, key_cond))\n",
    "            self.optimizer_G.zero_grad()\n",
    "            g_loss.backward()\n",
    "            self.optimizer_G.step()\n",
    "\n",
    "            # Log and save\n",
    "            if epoch % 50 == 0:\n",
    "                print(\n",
    "                    f\"Epoch {epoch}, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "                self.generator.eval()\n",
    "                with torch.no_grad():\n",
    "                    z = torch.randn(1, self.config.latent_dim,\n",
    "                                    device=self.device)\n",
    "                    key_cond = torch.tensor([0], device=self.device)  # C major\n",
    "                    gen = self.generator(z, key_cond).cpu().numpy().squeeze(0)\n",
    "                    binary = (gen > np.random.uniform(\n",
    "                        0.3, 0.7, gen.shape)).astype(int)\n",
    "                    self.midi_converter.piano_roll_to_midi(\n",
    "                        binary, f\"{self.config.output_dir}/generated_epoch_{epoch:04}_cmajor.mid\")\n",
    "                self.generator.train()\n",
    "                torch.save(self.generator.state_dict(\n",
    "                ), f\"{self.config.output_dir}/generator_epoch_{epoch:04}.pth\")\n",
    "        #model = self.generator.state_dict()\n",
    "        #visualkeras.layered_view(model).show() # display using your system viewer\n",
    "        #visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
    "        #visualkeras.layered_view(model, to_file='output.png').show() # write and show\n",
    "\n",
    "        #visualkeras.layered_view(model)\n",
    "\n",
    "        # Final output for multiple keys\n",
    "        self.generate_final_outputs()\n",
    "\n",
    "    def generate_final_outputs(self):\n",
    "        self.generator.eval()\n",
    "        key_names = [\"C_major\", \"C#_major\", \"D_major\", \"D#_major\", \"E_major\", \"F_major\", \"F#_major\",\n",
    "                     \"G_major\", \"G#_major\", \"A_major\", \"A#_major\", \"B_major\",\n",
    "                     \"C_minor\", \"C#_minor\", \"D_minor\", \"D#_minor\", \"E_minor\", \"F_minor\",\n",
    "                     \"F#_minor\", \"G_minor\", \"G#_minor\", \"A_minor\", \"A#_minor\", \"B_minor\"]\n",
    "        with torch.no_grad():\n",
    "            for key_idx in range(min(self.config.num_keys, 3)):\n",
    "                z = torch.randn(1, self.config.latent_dim, device=self.device)\n",
    "                key_cond = torch.tensor([key_idx], device=self.device)\n",
    "                gen = self.generator(z, key_cond).cpu().numpy().squeeze(0)\n",
    "                binary = (gen > 0.5).astype(int)\n",
    "                self.midi_converter.piano_roll_to_midi(\n",
    "                    binary, f\"{self.config.output_dir}/generated_final_{key_names[key_idx]}.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import torch  # Added import for torch\n",
    "import os\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, folder, max_files=1000):\n",
    "        self.folder = folder\n",
    "        self.max_files = max_files\n",
    "\n",
    "    #The estimate_key function in the DataLoader class analyzes a MIDI file's chroma distribution to determine its musical key by \n",
    "    #correlating it with major and minor key profiles. It returns an index representing the detected key (0–23 for 12 major and 12 minor keys), defaulting to C major (0) \n",
    "    #if an error occurs during processing.\n",
    "    #Musical key signatures\n",
    "    def estimate_key(self, midi_data):\n",
    "        try:\n",
    "            chroma = midi_data.get_chroma(fs=8)\n",
    "            chroma_sum = np.sum(chroma, axis=1)\n",
    "            major_profile = np.array(\n",
    "                [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
    "            minor_profile = np.array(\n",
    "                [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
    "            scores = []\n",
    "            for i in range(12):\n",
    "                shifted_major = np.roll(major_profile, i)\n",
    "                shifted_minor = np.roll(minor_profile, i)\n",
    "                scores.append((np.correlate(chroma_sum, shifted_major)[0], i))\n",
    "                scores.append(\n",
    "                    (np.correlate(chroma_sum, shifted_minor)[0], i + 12))\n",
    "            best_score, key_idx = max(scores)\n",
    "            return key_idx\n",
    "        except:\n",
    "            return 0  # Default to C major\n",
    "\n",
    "\n",
    "    #The midi_to_piano_roll function in the DataLoader class converts a MIDI file into a binary piano roll representation using pretty_midi, \n",
    "    #with dimensions (128 notes, specified time steps) at a given sampling frequency (e.g., 8 Hz). \n",
    "    # It pads or truncates the sequence to match the desired length, ensuring compatibility with the model’s input requirements, \n",
    "    #and returns None if processing fails due to invalid MIDI data.\n",
    "    def midi_to_piano_roll(self, file_path, fs=8, n_notes=128, length=32):\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "            piano_roll = midi_data.get_piano_roll(fs=fs)\n",
    "            piano_roll = (piano_roll > 0).astype(np.float32)\n",
    "            if piano_roll.shape[1] < length:\n",
    "                pad = length - piano_roll.shape[1]\n",
    "                piano_roll = np.pad(\n",
    "                    piano_roll, ((0, 0), (0, pad)), mode='constant')\n",
    "            else:\n",
    "                piano_roll = piano_roll[:, :length]\n",
    "            if piano_roll.shape != (n_notes, length):\n",
    "                raise ValueError(\n",
    "                    f\"Invalid piano roll shape: {piano_roll.shape}, expected ({n_notes}, {length})\")\n",
    "            return piano_roll\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Data set -> https://codeload.github.com/jukedeck/nottingham-dataset/zip/refs/heads/master\n",
    "    def load_data(self):\n",
    "        X, keys = [], []\n",
    "        for i, file in enumerate(os.listdir(self.folder)):\n",
    "            if file.endswith((\".mid\", \".midi\")):\n",
    "                file_path = os.path.join(self.folder, file)\n",
    "                roll = self.midi_to_piano_roll(file_path)\n",
    "                if roll is not None:\n",
    "                    X.append(roll)\n",
    "                    midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "                    key_idx = self.estimate_key(midi_data)\n",
    "                    keys.append(key_idx)\n",
    "                if i >= self.max_files - 1:\n",
    "                    break\n",
    "        if not X:\n",
    "            raise ValueError(\"No valid MIDI files loaded\")\n",
    "        X = np.array(X)\n",
    "        assert X.shape[1:] == (\n",
    "            128, 32), f\"Loaded data shape mismatch: {X.shape}\"\n",
    "        return torch.tensor(X, dtype=torch.float32).reshape(-1, 128, 32), torch.tensor(keys, dtype=torch.long)\n",
    "\n",
    "\n",
    "class MidiConverter:\n",
    "    def piano_roll_to_midi(self, piano_roll, output_path, fs=8, min_duration=2):\n",
    "        if len(piano_roll.shape) == 1 and piano_roll.shape[0] == 128 * 32:\n",
    "            print(\"Auto reshaping piano roll from (4096,) to (128, 32)\")\n",
    "            piano_roll = piano_roll.reshape(128, 32)\n",
    "        if len(piano_roll.shape) != 2 or piano_roll.shape != (128, 32):\n",
    "            print(\"Error: piano_roll should be shape (128, 32). Got:\",\n",
    "                  piano_roll.shape)\n",
    "            return\n",
    "        midi = pretty_midi.PrettyMIDI()\n",
    "        instrument = pretty_midi.Instrument(\n",
    "            program=0, name=\"Acoustic Grand Piano\")\n",
    "        time_step = 1.0 / fs\n",
    "        for pitch in range(piano_roll.shape[0]):\n",
    "            is_note_on = False\n",
    "            start = 0\n",
    "            for t in range(piano_roll.shape[1]):\n",
    "                if piano_roll[pitch, t] > 0 and not is_note_on:\n",
    "                    start = t\n",
    "                    is_note_on = True\n",
    "                elif (piano_roll[pitch, t] == 0 or t == piano_roll.shape[1] - 1) and is_note_on:\n",
    "                    end = t if piano_roll[pitch, t] == 0 else t + 1\n",
    "                    if end - start >= min_duration:\n",
    "                        note = pretty_midi.Note(\n",
    "                            velocity=100,\n",
    "                            pitch=pitch,\n",
    "                            start=start * time_step,\n",
    "                            end=end * time_step\n",
    "                        )\n",
    "                        instrument.notes.append(note)\n",
    "                    is_note_on = False\n",
    "        midi.instruments.append(instrument)\n",
    "        midi.write(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962005c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 256\n",
    "        self.note_dim = 128\n",
    "        self.time_steps = 32\n",
    "        self.num_keys = 24\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 5000\n",
    "        self.n_critic = 5\n",
    "        self.lr = 0.0001\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.9\n",
    "        self.gradient_penalty_weight = 10\n",
    "        self.output_dir = \"C:/mtechpracticals/semester-3/gen-ai/genai-midi-generator-v1-pynb/output\"\n",
    "        self.data_dir = \"C:/mtechpracticals/semester-3/gen-ai/genai-midi-generator-v3-oop/data\"\n",
    "        self.max_files = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# public static void main(String args[]) . . as of now leave the arguements part. \n",
    "if __name__ == \"__main__\":\n",
    "    config = Config()  # Create an instance of the Config class\n",
    "    trainer = GANTrainer(config)\n",
    "    trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
